{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máster en Big Data y Data Science\n",
    "\n",
    "### Metodologías de gestión y diseño de proyectos de big data\n",
    "\n",
    "#### AP2 - Modelado\n",
    "\n",
    "---\n",
    "\n",
    "En esta libreta se comienzan a ejecutar las actividades correspondientes a la fase de modelado. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de librerias a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las librerias a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Para registro de toda la experimentación\n",
    "import mlflow\n",
    "\n",
    "# Para la generación de los sets de train - test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importaciones varias para la evaluación\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura del dataset generado previamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace la lectura del dataset del seminario y se obtiene su cabecera\n",
    "datos = pd.read_csv('../../data/final/datos_finales.csv', sep=';')\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de meta-datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporte_descripcion_dataset(df):\n",
    "    columnas = df.columns\n",
    "    print(\"Columnas del dataset:\\n\")\n",
    "    for col in columnas:\n",
    "        print(col)\n",
    "    print(f\"\\nCantidad de filas: {df.shape[0]}\")\n",
    "\n",
    "print(\"Descripción del dataset 'datos_completos'\")\n",
    "reporte_descripcion_dataset(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado de los sets de entrenamiento y testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se separan los atributos de datos de los de la etiqueta del dataset\n",
    "\n",
    "labels = datos.falta_pago.values\n",
    "\n",
    "features = datos[['operaciones_ult_12m', 'gastos_ult_12m', 'limite_credito_tc',\n",
    "       'antiguedad_cliente', 'tasa_interes', 'ingresos', 'pct_ingreso',\n",
    "       'antiguedad_empleado', 'edad', 'importe_solicitado', 'duracion_credito',\n",
    "       'situacion_vivienda', 'objetivo_credito', 'estado_civil_N',\n",
    "       'estado_credito_N', 'estado_cliente', 'genero',\n",
    "       'nivel_educativo', 'personas_a_cargo']]\n",
    "\n",
    "print(f\"Vista de los datos del atributo target: \\n{labels[:10]}\")\n",
    "print(\"-\"*50)\n",
    "print(\"Vista parcial de los datos sin el atributo target:\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se pasa a binarizar los atributos\n",
    "\n",
    "data = pd.get_dummies(features)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para evitar problemas con mlfow se hace una conversión de integer a double \n",
    "# de los atributos: 'importe_solicitado', 'duracion_credito', 'estado_credito'\n",
    "\n",
    "# Se filtran las columnas del tipo integer\n",
    "integer_columns = data.select_dtypes(include='int').columns\n",
    "\n",
    "# Convert integer columns to double\n",
    "data[integer_columns] = data[integer_columns].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se reparten los datos disponibles en conjuntos para entrenamiento y testeo\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels) \n",
    "\n",
    "# Toma por defecto 75% (entrenamiento) - 25% (testeo)\n",
    "\n",
    "# Vista de los datos de entrenamiento para una fila\n",
    "\n",
    "print(f\"Un registro de entrenamiento: \\n{train_data.iloc[1]}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"Label del registro: \\n{train_labels[1]}\\n\")\n",
    "\n",
    "print(\"#\"*50)\n",
    "print(\"#\"*50)\n",
    "\n",
    "# Vista de los datos de testeo para una fila\n",
    "\n",
    "print(f\"\\nUn registro de testeo: \\n{test_data.iloc[1]}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"Label del registro: \\n{test_labels[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de la evaluación\n",
    "\n",
    "def evaluar_modelo(modelo, test_data, test_labels):\n",
    "    prediction = modelo.predict(test_data)\n",
    "    print('Rendimiento obtenido:',accuracy_score(test_labels,prediction))\n",
    "    print('Reporte de indicadores:\\n',classification_report(test_labels,prediction))\n",
    "    print('Matriz de confusión:')\n",
    "    cm = confusion_matrix(test_labels, prediction, labels=modelo.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                   display_labels=modelo.classes_)\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obtener todos los parámetros y no solo los modificados\n",
    "\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(print_changed_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de modelos\n",
    "\n",
    "#### ZeroR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf = DummyClassifier()\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(test_data)\n",
    "\n",
    "print('Rendimiento obtenido:',accuracy_score(test_labels, prediction))\n",
    "print('Vista de una muestra de valores de predicción y datos de testeo:')\n",
    "print(prediction[:10])\n",
    "print(test_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Se pasa a configurar la serie de experimentos en **mlflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se establece un nombre para identificar la serie de experimentos\n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"Prueba #1\")\n",
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "with mlflow.start_run(run_name='Logistic Regression'):\n",
    "    lreg = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "    lreg.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluar_modelo(lreg, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "with mlflow.start_run(run_name='KNN'):\n",
    "    knn = KNeighborsClassifier(n_neighbors=50, \n",
    "                               algorithm = 'ball_tree', \n",
    "                               leaf_size = 25)\n",
    "\n",
    "    knn.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluar_modelo(knn, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árboles de Decisión (TDIDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "with mlflow.start_run(run_name='Decision Tree'):\n",
    "    dtc = DecisionTreeClassifier(max_depth=3, \n",
    "                                 criterion='entropy', \n",
    "                                 min_samples_split=10)\n",
    "\n",
    "    dtc.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluar_modelo(dtc, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(dtc, filled=True, feature_names=data.columns, class_names=labels)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métodos de ensamblado de modelos: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "with mlflow.start_run(run_name='Random Forest'):\n",
    "    rndf = RandomForestClassifier(n_estimators=10)\n",
    "    rndf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluar_modelo(rndf, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Prueba #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(experiment_name=\"Prueba #2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='Decision Tree (#2)'):\n",
    "    dtc = DecisionTreeClassifier(max_depth=5, \n",
    "                                 criterion='entropy', \n",
    "                                 min_samples_split=15)\n",
    "\n",
    "    dtc.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Salida de resultado de la evaluación correspondientes a la Prueba #2\")\n",
    "evaluar_modelo(dtc, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: posibilidades de mejora de la libreta\n",
    "\n",
    "* Evaluación del clasificador a través de validación cruzada\n",
    "* Ejecutar pruebas que contemplen datos con mayor o menor grado de transformaciones aplicadas \n",
    "* Implementar clasificación con otras técnicas (por ejemplo: redes neuronales, SVM, entre otras)\n",
    "* Evaluar la combinación de técnicas, por ejemplo: clustering y sobre esos resultados aplicación de árboles de decisión para detectar patrones de agrupamiento y ahí relacionarlo con la situación de los clientes.\n",
    "* Integrar técnicas de extracción de reglas de asociación (con mayor \"legibilidad\" para usuarios no-técnicos)\n",
    "* Entre otras opciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Prueba de despliegue (utilzando datos nuevos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_nuevos = pd.read_csv('../../data/final/datos_nuevos.csv', sep=';')\n",
    "datos_nuevos.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante**: recordar que si se implementan operaciones de transformación sobre los datos será necesario (posiblemente) replicarlas sobre los datos nuevos para que ambos datasets sean compatibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se tienen que aplicar las adaptaciones realizadas sobre los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columna: estado_civil\n",
    "cambios_estado_civil = {\n",
    "    'CASADO' : 'C',\n",
    "    'SOLTERO' : 'S',\n",
    "    'DESCONOCIDO' : 'N',\n",
    "    'DIVORCIADO' : 'D',\n",
    "}\n",
    "\n",
    "estado_civil_N = datos_nuevos.loc[:, ('estado_civil')].map(cambios_estado_civil).rename('estado_civil')\n",
    "\n",
    "# Columna: estado_credito\n",
    "cambios_estado_credito = {\n",
    "    0: 'C',\n",
    "    1 : 'P',\n",
    "}\n",
    "\n",
    "estado_credito_N = datos_nuevos.loc[:, ('estado_credito')].map(cambios_estado_credito).rename('estado_credito')\n",
    "\n",
    "# df_final = pd.concat([estado_civil_N, estado_credito_N, df_integrado], axis=1)\n",
    "# df_final.head()\n",
    "\n",
    "# Antiguedad del empleado\n",
    "\n",
    "etiquetas_a_e = ['menor_10', '5_a_10', 'mayor_10']\n",
    "rangos_a_e = [0, 4, 10, 50]\n",
    "valor_para_nan = 'NA'\n",
    "antiguedad_empleados_N = pd.cut(datos_nuevos['antiguedad_empleado'], \n",
    "                                bins=rangos_a_e, \n",
    "                                labels=etiquetas_a_e,\n",
    "                                right=False).cat.add_categories(valor_para_nan).fillna(valor_para_nan)\n",
    "\n",
    "# antiguedad_empleados_N.value_counts()\n",
    "\n",
    "# edad\n",
    "\n",
    "etiquetas_e = ['menor_25', '25_a_30']\n",
    "rangos_e = [0, 24, 50]\n",
    "edad_N = pd.cut(datos_nuevos['edad'], \n",
    "                                bins=rangos_e, \n",
    "                                labels=etiquetas_e)\n",
    "\n",
    "# edad_N.value_counts()\n",
    "\n",
    "# pct_ingreso\n",
    "\n",
    "etiquetas_p_i = ['hasta_20', '20_a_40', '40_a_60', 'mayor_60']\n",
    "rangos_p_i = [0, 0.19, 0.39, 0.60, 0.99]\n",
    "pct_ingreso_N = pd.cut(datos_nuevos['pct_ingreso'], \n",
    "                                bins=rangos_p_i, \n",
    "                                labels=etiquetas_p_i)\n",
    "\n",
    "# pct_ingreso_N.value_counts()\n",
    "\n",
    "# ingresos\n",
    "\n",
    "etiquetas_i = ['hasta_20k', '20k_a_50k', '50k_a_100k', 'mayor_100k']\n",
    "rangos_i = [0, 19999, 49999, 99999, 999999]\n",
    "ingresos_N = pd.cut(datos_nuevos['ingresos'], \n",
    "                                bins=rangos_i, \n",
    "                                labels=etiquetas_i)\n",
    "\n",
    "# ingresos_N.value_counts()\n",
    "\n",
    "# tasa_interes\n",
    "\n",
    "etiquetas_t_i = ['hasta_7p', '7p_a_15p', '15p_a_20p', 'mayor_20p']\n",
    "rangos_t_i = [0, 6.99, 14.99, 19.99, 100]\n",
    "tasa_interes_N = pd.cut(datos_nuevos['tasa_interes'], \n",
    "                                bins=rangos_t_i, \n",
    "                                labels=etiquetas_t_i)\n",
    "\n",
    "# tasa_interes_N.value_counts()\n",
    "\n",
    "# antiguedad_cliente\n",
    "\n",
    "etiquetas_a_c = ['menor_2y', '2y_a_4y', 'mayor_4y']\n",
    "rangos_a_c = [0, 24, 48, 100]\n",
    "antiguedad_cliente_N = pd.cut(datos_nuevos['antiguedad_cliente'], \n",
    "                                bins=rangos_a_c, \n",
    "                                labels=etiquetas_a_c)\n",
    "\n",
    "# antiguedad_cliente_N.value_counts()\n",
    "\n",
    "# limite_credito_tc\n",
    "\n",
    "etiquetas_l_tc = ['menor_3k', '3k_a_5k', '5k_a_10k', 'mayor_10k']\n",
    "rangos_l_tc = [0, 2999, 4999, 9999, 100000]\n",
    "limite_credito_tc_N = pd.cut(datos_nuevos['limite_credito_tc'], \n",
    "                                bins=rangos_l_tc, \n",
    "                                labels=etiquetas_l_tc)\n",
    "\n",
    "# limite_credito_tc_N.value_counts()\n",
    "\n",
    "# gastos_ult_12m\n",
    "\n",
    "etiquetas_g_u12 = ['menor_1k', '2k_a_4k', '4k_a_6k', '6k_a_8k', '8k_a_10k', 'mayor_10k']\n",
    "rangos_g_u12 = [0, 999, 3999, 5999, 7999, 9999, 100000]\n",
    "gastos_ult_12m_N = pd.cut(datos_nuevos['gastos_ult_12m'], \n",
    "                                bins=rangos_g_u12, \n",
    "                                labels=etiquetas_g_u12)\n",
    "\n",
    "# gastos_ult_12m_N.value_counts()\n",
    "\n",
    "# operaciones_ult_12m\n",
    "\n",
    "etiquetas_o_u12 = ['menor_15', '15_a_30', '30_a_50', '50_a_75', '75_a_100', 'mayor_100']\n",
    "rangos_o_u12 = [0, 14, 29, 49, 74, 99, 1000]\n",
    "operaciones_ult_12m_N = pd.cut(datos_nuevos['operaciones_ult_12m'], \n",
    "                                bins=rangos_o_u12, \n",
    "                                labels=etiquetas_o_u12)\n",
    "\n",
    "# operaciones_ult_12m_N.value_counts()\n",
    "\n",
    "col_eliminar_final = [\n",
    "              'edad',\n",
    "              'antiguedad_empleado',\n",
    "              'antiguedad_cliente', \n",
    "              'ingresos',\n",
    "              'pct_ingreso', \n",
    "              'tasa_interes',\n",
    "              'gastos_ult_12m', \n",
    "              'limite_credito_tc', \n",
    "              'operaciones_ult_12m',\n",
    "              'nivel_tarjeta',\n",
    "              'estado_civil',\n",
    "              'estado_credito',\n",
    "              'id_cliente']\n",
    "\n",
    "datos_nuevos.drop(col_eliminar_final, inplace=True, axis=1)\n",
    "\n",
    "\n",
    "df_nuevo = pd.concat([operaciones_ult_12m_N, gastos_ult_12m_N, limite_credito_tc_N, antiguedad_cliente_N, tasa_interes_N, ingresos_N, pct_ingreso_N, antiguedad_empleados_N, edad_N, estado_civil_N, estado_credito_N, datos_nuevos], axis=1)\n",
    "df_nuevo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_codif = pd.get_dummies(df_nuevo)\n",
    "nuevos_codif.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que puede haber diferencias con el set de entrenamiento se emparejan\n",
    "\n",
    "columnas_faltantes = set(data.columns) - set(nuevos_codif.columns)\n",
    "display(columnas_faltantes)\n",
    "for columna in columnas_faltantes:\n",
    "    nuevos_codif[columna] = 0 # Se agregan las columnas faltantes con valor 0\n",
    "\n",
    "print('Datos nuevos: ' + str(len(nuevos_codif.columns)))\n",
    "print('Datos entrenamiento: ' + str(len(data.columns)))\n",
    "print(set(data.columns) - set(nuevos_codif.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_codif = nuevos_codif[data.columns]\n",
    "nuevos_codif.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace la predicción con los nuevos datos\n",
    "\n",
    "prediccion_nuevos = dtc.predict(nuevos_codif)\n",
    "\n",
    "prediccionDF = pd.DataFrame(prediccion_nuevos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se agrega la nueva columna\n",
    "datos_nuevos['prediccion_mora'] = prediccionDF\n",
    "datos_nuevos['prediccion_mora'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
